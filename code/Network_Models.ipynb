{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL36NqEaz5tZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c30f6b3-2fee-4837-8ad3-809e00ab4883"
      },
      "source": [
        "pip install Pillow==2.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow==2.2.2 in /usr/local/lib/python3.6/dist-packages (2.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d44jkMEC5-TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2UbScML5-AZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "c36db9a2-0900-4a7c-d75c-6585875dadfb"
      },
      "source": [
        "!pip install tensorflow==1.12.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n",
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 71kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.27.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 19.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.34.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.2.1)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Found existing installation: tensorflow 2.2.0rc1\n",
            "    Uninstalling tensorflow-2.2.0rc1:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc1\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMLBV4RYEyCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from keras import Input\n",
        "from keras.applications import VGG19\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense, PReLU, Flatten\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras_preprocessing.image import img_to_array, load_img\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pKn3Xb6u8h",
        "colab_type": "text"
      },
      "source": [
        "Method to create Residual Block\n",
        "* The output of the pre-residual block goes to the first residual block. The output of the first residual block goes to the second residual block, and so on, up to the 16th residual block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L7R9k8H4xpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_block(x):\n",
        "    \"\"\"\n",
        "    Residual block\n",
        "    \"\"\"\n",
        "    filters = [64, 64]\n",
        "    kernel_size = 3\n",
        "    strides = 1\n",
        "    padding = \"same\"\n",
        "    momentum = 0.8\n",
        "    activation = \"relu\"\n",
        "\n",
        "    res = Conv2D(filters=filters[0], kernel_size=kernel_size, \n",
        "                 strides=strides, padding=padding)(x)\n",
        "    res = Activation(activation=activation)(res)\n",
        "    res = BatchNormalization(momentum=momentum)(res)\n",
        "\n",
        "    res = Conv2D(filters=filters[1], kernel_size=kernel_size, \n",
        "                 strides=strides, padding=padding)(res)\n",
        "    res = BatchNormalization(momentum=momentum)(res)\n",
        "\n",
        "    # Add res and x\n",
        "    res = Add()([res, x])\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_3AcZzH-vmA",
        "colab_type": "text"
      },
      "source": [
        "## The Generator Network\n",
        "* Defining hyperparameters\n",
        "* Gen1 - Creating Input layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apxRkgHn7KnX",
        "colab_type": "text"
      },
      "source": [
        "##### Model Architecture\n",
        "* Gen2 -Add the post-residual block (a 2D conv layer followed by a batch normalization layer)\n",
        "* Gen3 -Add an Add layer to take the sum of the output from the pre-residual block, which is gen1, and the output from the post-residual block, which is Gen2.\n",
        "* Gen4 & Gen5 -add up the unsampling block\n",
        "* Gen6 -Output Conv-layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZXcp3ww64xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Build_Generator():\n",
        "\n",
        "  residual_blocks = 16\n",
        "  momentum = 0.8\n",
        "  input_shape = (64, 64, 3)\n",
        "\n",
        "  input_layer = Input(shape=input_shape)\n",
        "  gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same', activation='relu')(input_layer)\n",
        "\n",
        "  res = residual_block(gen1)\n",
        "  for i in range(residual_blocks - 1):\n",
        "    res = residual_block(res)\n",
        "\n",
        "  \n",
        "  gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
        "  gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
        "  gen3 = Add()([gen2, gen1]) # This layer generates another tensor of similar shape.\n",
        "\n",
        "\n",
        "  gen4 = UpSampling2D(size=2)(gen3)\n",
        "  gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
        "  gen4 = Activation('relu')(gen4)\n",
        "\n",
        "\n",
        "  gen5 = UpSampling2D(size=2)(gen4)\n",
        "  gen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\n",
        "  gen5 = Activation('relu')(gen5)\n",
        "\n",
        "  gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen5)\n",
        "  output = Activation('tanh')(gen6)\n",
        "\n",
        "  model_gen = Model(inputs=[input_layer], outputs=[output], name='generator') \n",
        "\n",
        "  return model_gen\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSH3qVh5_V4I",
        "colab_type": "text"
      },
      "source": [
        "## The Discriminator Network\n",
        "____\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-O3HMjrBJiI",
        "colab_type": "text"
      },
      "source": [
        "### Configuration:\n",
        "* hyperparameters required for the discriminator network\n",
        "* Dist - Adding a convolution block.\n",
        "* Dist1-Dist8 are 8 convolution blocks.\n",
        "* Dist9 -Add a dense layer with 1,024 nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFGidEFOBA22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Build_Discriminator():\n",
        "  # Introducing Hyperparameter Requires.\n",
        "  leakyrelu_alpha = 0.2   \n",
        "  momentum = 0.8\n",
        "  input_shape = (256, 256, 3)\n",
        "\n",
        "  input_layer = Input(shape=input_shape) # Model's Input Layer. \n",
        "\n",
        "\n",
        "  dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
        "  dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
        "  print(\"Dist1 is created..\")\n",
        "\n",
        "\n",
        "  dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
        "  dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
        "  dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
        "  print(\"Dist2 is created..\")\n",
        "\n",
        "\n",
        "  dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
        "  dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
        "  dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
        "  print(\"Dist3 is created..\")\n",
        "\n",
        "\n",
        "  dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
        "  dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
        "  dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
        "  print(\"Dist4 is created..\")\n",
        "\n",
        "\n",
        "  dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n",
        "  dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
        "  dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
        "  print(\"Dist5 is created..\")\n",
        "\n",
        "\n",
        "  dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
        "  dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
        "  dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
        "  print(\"Dist6 is created..\")\n",
        "\n",
        "\n",
        "  dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
        "  dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
        "  dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
        "  print(\"Dist7 is created..\")\n",
        "\n",
        "  dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
        "  dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
        "  dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
        "  print(\"Dist8 is created..\")\n",
        "\n",
        "  dis9 = Dense(units=1024)(dis8) #Nodes = 1024\n",
        "  dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
        "  output = Dense(units=1, activation='sigmoid')(dis9) # Dense layer to return probabilities.\n",
        "  print(\"Dense layer is created..\")\n",
        "\n",
        "  model_dist = Model(inputs=[input_layer], outputs=[output], \n",
        "                name='discriminator')\n",
        "\n",
        "  print(\"Discriminator Model created..\")\n",
        "  return model_dist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ez4ecCVGwDa",
        "colab_type": "text"
      },
      "source": [
        "## The adversarial network\n",
        "The adversarial network is a combined network that uses the generator, the discriminator and VGG19.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_i4mtBaHyoJ",
        "colab_type": "text"
      },
      "source": [
        "____\n",
        "###Configuration:\n",
        "* 1 -creating an input layer of the network \n",
        "** The adversarial network will receive an image of a shape of (64, 64, 3), which is why we have created an input layer.\n",
        "* 2 -generate fake high-resolution images using the generator network\n",
        "* 3 -extract the features of the fake images using the VGG19 network\n",
        "* 4 -make the discriminator network non-trainable in the adversarial network.\n",
        "** We are making the discriminator network non-trainable because we don’t want to train the discriminator network while we train the generator network.\n",
        "\n",
        "* 5 -pass the fake images to the discriminator network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t48fqW6YDYAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_adversarial_model(generator, discriminator, vgg):\n",
        "\n",
        "    #1\n",
        "    input_low_resolution = Input(shape=(64, 64, 3))\n",
        "\n",
        "    #2\n",
        "    fake_hr_images = generator(input_low_resolution)\n",
        "    #3\n",
        "    fake_features = vgg(fake_hr_images)\n",
        "\n",
        "    #4\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    #5\n",
        "    output = discriminator(fake_hr_images)\n",
        "    \n",
        "    # Creating Model.\n",
        "    model_adv = Model(inputs=[input_low_resolution], outputs=[output, fake_features])\n",
        "\n",
        "    for layer in model.layers:\n",
        "        print(layer.name, layer.trainable)\n",
        "\n",
        "    print(model.summary())\n",
        "    return model_adv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmbXhiFaWoNl",
        "colab_type": "text"
      },
      "source": [
        "## Training the SRGAN\n",
        "\n",
        "Training the SRGAN network is a two-step process. In the first step, we train the discriminator network. In the second step, we train the adversarial network, which eventually trains the generator network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPkVZWR7Jeuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"\"\n",
        "epochs = 20000\n",
        "batch_size = 1\n",
        "\n",
        "# Shape of low-resolution and high-resolution images\n",
        "low_resolution_shape = (64, 64, 3)\n",
        "high_resolution_shape = (256, 256, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}